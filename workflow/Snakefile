"""
@author: Katherine Eaton
SARS-CoV-2 Recombinant Detection Pipeline.
"""

# -----------------------------------------------------------------------------#
#                             Modules and Packages                             #
# -----------------------------------------------------------------------------#
import os
import copy
import textwrap
import datetime
import subprocess
import pandas as pd
import json

# Enforce minimum version
from snakemake.utils import min_version
min_version("7.3.6")

# -----------------------------------------------------------------------------#
# Setup
# -----------------------------------------------------------------------------#

today = datetime.date.today()

# Begin Code: https://github.com/nextstrain/ncov/blob/master/Snakefile

# Store the user's configuration prior to loading defaults. We need to make a deep
# copy because Snakemake will deep merge the dictionary later, modifying the values
# of a reference or shallow copy. Note that this loading of
# the user's config prior to the defaults below depends on the order Snakemake
# loads its configfiles. Specifically, the order of config loading is:
#
# 1. First, configfile arguments are loaded and config is built from these [1].
# 2. Then, config arguments are loaded and override existing config keys [2].
# 3. Then, the Snakefile is parsed and configfile directive inside the Snakefile is processed [3].
#    When configfile is loaded from the directive in the Snakefile, the config
#    dictionary is deep merged with the files [4] from the externally provided
#    config files. This is the only place the deep merge happens using the
#    update_config function [5].

# Load the default parameters
configfile: "defaults/parameters.yaml"

# Convert config into an OrderedDict with keys of "name" for use by the pipeline.
if isinstance(config.get("inputs"), list):
    config["inputs"] = OrderedDict((v["name"], v) for v in config["inputs"])
if isinstance(config.get("builds"), list):
    config["builds"] = OrderedDict((v["name"], v) for v in config["builds"])
if isinstance(config.get("rule_params"), list):
    config["rule_params"] = OrderedDict((v["name"], v) for v in config["rule_params"])

# Check for missing inputs.
if "inputs" not in config:
    logger.error("ERROR: Your workflow does not define any input files to start with.")
    logger.error("Update your configuration file (e.g., 'builds.yaml') to define at least one input dataset as follows and try running the workflow again:")
    logger.error(textwrap.indent(
        f"\ninputs:\n  name: local-data\n  metadata: data/example_metadata.tsv\n  sequences: data/example_sequences.fasta.gz\n",
        "  "
    ))
    sys.exit(1)

# Check for missing builds
if "builds" not in config:
    logger.error("ERROR: Your workflow does not define any builds to start with.")
    logger.error("Update your configuration file (e.g., 'builds.yaml') to define at least one build as follows and try running the workflow again:")
    logger.error(textwrap.indent(
        f"\nbuilds:\n  name: example-build\n",
        "  "
    ))
    sys.exit(1)

# End Code: https://github.com/nextstrain/ncov/blob/master/Snakefile

# Set default rule parameters for each build
for build in config["builds"]:
  for rule in config["rule_params"]:
    # Case 1. There are no params for this rule in the build
    if rule not in config["builds"][build]:
      config["builds"][build][rule] = config["rule_params"][rule]
    # Case 2. There are some params for this rule in the build
    else:
      for param in config["rule_params"][rule]:
        # Case 3. This param has not been specified
        if param not in config["builds"][build][rule]:
          config["builds"][build][rule][param] = config["rule_params"][rule][param]


BUILDS = list(config["builds"].keys())
USHER_INPUTS = [input for input in config["inputs"] if "usher" in config["inputs"][input]["type"]]
LOCAL_INPUTS = [input for input in config["inputs"] if "local" in config["inputs"][input]["type"]]

# Delete generic params (they've all been added to each build at this point)
config.pop("rule_params", None)

# -----------------------------------------------------------------------------#
#  Default Target
# -----------------------------------------------------------------------------#

rule all:
  """
  Default workflow targets.
  """
    input:
        # Stage 1: Nextclade
        expand("results/{build_name}/nextclade.recombinants.txt",
          build_name=BUILDS,
          ),
        # Stage 2: sc2rf
        expand("results/{build_name}/sc2rf.recombinants.txt",
          build_name=BUILDS,
          ),
        # Stage 3: UShER
        expand("results/{build_name}/subtrees_collapse",
          build_name=BUILDS,
          ),
        # Stage 4: Linelist
        expand("results/{build_name}/linelist.tsv",
          build_name=BUILDS,
          ),
        # Stage 5: Report
        expand("results/{build_name}/report.pptx",
          build_name=BUILDS,
          ),
# -----------------------------------------------------------------------------#
#  Accessory Rules
# -----------------------------------------------------------------------------#

rule print_config:
  """
  Print full config.
  """
  message: "Printing full config."
  run:
    # Print the config
    config_json = json.dumps(config, indent = 2)
    print(config_json)

    # Save to json files
    for build in BUILDS:
      outfile_dir = os.path.join("results", build)
      if not os.path.exists(outfile_dir):
        os.mkdir(outfile_dir)
      outfile_path = os.path.join(outfile_dir, "config.json")
      with open(outfile_path, "w") as outfile:
        outfile.write(config_json)


# -----------------------------------------------------------------------------#
rule help:
  """
  Print list of all rules and targets with help.
  """
  run:
    for rule in workflow.rules:
      print("-" * 160)
      print("rule: ", rule.name )
      if rule.docstring:
          print(rule.docstring)
      if rule._input:
          print("\tinput:")
          for in_file in rule.input:
              print("\t\t" + str(in_file))
          for in_file in rule.input.keys():
              print("\t\t" + in_file + ": " + str(rule.input[in_file]))
      if rule._output:
          print("\toutput:")
          for out_file in rule.output:
              print("\t\t" + out_file)
          for out_file in rule.output.keys():
              print("\t\t" + out_file + ": " + str(rule.output[out_file]))
      if rule._params:
          print("\tparams:")
          for param in rule.params.keys():
              print("\t\t" + param + ": " + str(rule.params[param]))
      if rule.resources:
          print("\tresources:")
          for resource in rule.resources.keys():
              print("\t\t" + resource + ": " + str(rule.resources[resource]))
      if rule.conda_env:
          print("\t\tconda: ", rule.conda_env)
      if rule._log:
          print("\t\tlog: ", rule._log)

# -----------------------------------------------------------------------------#
#  STAGE 0: Setup
# -----------------------------------------------------------------------------#

rule_name = "issues_download"
rule issues_download:
  """
  Download pango-designation issues.
  """
  message: """Downloading pango-designation issues.\n
  log:     logs/{rule}/{today}.log
  issues:  resources/issues.tsv
  """.format(today=today, rule=rule_name)
  
  input:
    breakpoints = "resources/breakpoints.tsv",
  output:
    issues = "resources/issues.tsv",
    issue_to_lineage = "resources/issue_to_lineage.tsv",
  threads: 1
  resources:
    cpus = 1,
  benchmark:
    "benchmarks/{rule}/{today}.tsv".format(today=today, rule=rule_name),
  log:
    "logs/{rule}/{today}.log".format(today=today, rule=rule_name),
  shell:
    """
    python3 resources/issues.py --breakpoints {input.breakpoints} 1> {output.issues} 2> {log};
    csvtk cut -t -f "issue,lineage" {output.issues} | tail -n+2   1> {output.issue_to_lineage} 2>> {log};
    """

# -----------------------------------------------------------------------------#
#  STAGE 1: Nextclade QC
# -----------------------------------------------------------------------------#

rule_name = "nextclade_dataset"
rule nextclade_dataset:
  """
  Download Nextclade dataset.
  """

  message: """Downloading Nextclade dataset.\n
  log:     logs/{rule}/{{wildcards.dataset}}_{{wildcards.tag}}_{today}.log
  dataset: data/{{wildcards.dataset}}_{{wildcards.tag}}
  """.format(today=today, rule=rule_name)

  wildcard_constraints:
    # The tag will always begin with the year (ex. 2022)
    tag="([0-9]){4}.*",
  output:
    dataset_dir = directory("data/{dataset}_{tag}"),
  threads: 1
  resources:
    cpus = 1,
  benchmark:
    "benchmarks/{rule}/{{dataset}}_{{tag}}_{today}.tsv".format(today=today, rule=rule_name),
  log:
    "logs/{rule}/{{dataset}}_{{tag}}_{today}.log".format(today=today, rule=rule_name),
  shell:
    """
    nextclade dataset get --name {wildcards.dataset} --tag {wildcards.tag} --output-dir {output.dataset_dir} > {log} 2>&1;
    """

# -----------------------------------------------------------------------------
# Nextclade

rule_name = "nextclade"

# Parameters function
def _params_nextclade(wildcards):
  """Parse parameters from wildcards for rule nextclade."""

  params = {}

  nextclade_ref = config["builds"][wildcards.build]["nextclade"]["nextclade_ref"]
  params["nextclade_ref"] = "{}".format(nextclade_ref)

  custom_ref = config["builds"][wildcards.build]["nextclade"]["custom_ref"]
  params["custom_ref"] = "{}".format(custom_ref)

  return params

# Snakemake rule
rule nextclade:
  """
  Align sequences and perform QC with Nextclade.
  """

  message: """Aligning sequences and performing QC with Nextclade.\n
  build:     {{wildcards.build}}
  log:       logs/{rule}/{{wildcards.build}}_{today}.log
  alignment: results/{{wildcards.build}}/nextclade.aligned.fasta
  qc:        results/{{wildcards.build}}/nextclade.qc.tsv
  metadata:  results/{{wildcards.build}}/nextclade.metadata.tsv 
  """.format(today=today, rule=rule_name)  
  input:
    dataset   = lambda wildcards: "data/{dataset}_{tag}".format(
                  dataset=config["builds"][wildcards.build]["nextclade_dataset"]["dataset"],
                  tag=config["builds"][wildcards.build]["nextclade_dataset"]["tag"],
                ),
    sequences = "data/{build}/sequences.fasta",
    metadata  = "data/{build}/metadata.tsv",
  output:
    metadata     = "results/{build}/nextclade.metadata.tsv",
    aligned      = "results/{build}/nextclade.aligned.fasta",
    translations = directory("results/{build}/translations"),
    qc           = "results/{build}/nextclade.qc.tsv",
    errors       = "results/{build}/nextclade.errors.csv",
  params:
    outdir        = "results/{build}",
    basename      = "nextclade",
    nextclade_ref = lambda wildcards: _params_nextclade(wildcards)["nextclade_ref"],
    custom_ref    = lambda wildcards: _params_nextclade(wildcards)["custom_ref"],
  benchmark:
    "benchmarks/{rule}/{{build}}_{today}.tsv".format(today=today, rule=rule_name),
  log:
    "logs/{rule}/{{build}}_{today}.log".format(today=today, rule=rule_name),
  shell:
    """
    nextclade run \
      --jobs {resources.cpus} \
      --input-fasta {input.sequences} \
      --input-dataset {input.dataset} \
      --include-reference \
      --output-dir {params.outdir} \
      --output-tsv {output.qc} \
      --output-fasta {output.aligned} \
      --output-basename {params.basename} \
      > {log} 2>&1;

    # Migrate translations output
    mkdir -p {params.outdir}/translations;
    mv {params.outdir}/{params.basename}.gene* {output.translations}/;
    mv {params.outdir}/{params.basename}.insertions* {output.translations}/;

    # Rename ref strain
    seqkit replace -p "{params.nextclade_ref}" -r "{params.custom_ref}" {output.aligned} \
      > {output.aligned}.tmp;
    mv {output.aligned}.tmp {output.aligned};

    # Merge QC output with metadata
    csvtk rename -t -f "seqName" -n "strain" {output.qc} \
      | csvtk merge -t -f "strain" {input.metadata} - \
      > {output.metadata}
    """

# ----------------------------------------------------------------------------#
rule_name = "nextclade_recombinants"

# Parameters function
def _params_nextclade_recombinants(wildcards):
  """Parse parameters from wildcards for rule nextclade_recombinants."""

  params = {}

  exclude_clades = config["builds"][wildcards.build]["nextclade_recombinants"]["exclude_clades"]
  params["exclude_clades"] = "{}".format("|".join(exclude_clades))

  return params

# Snakemake rule
rule nextclade_recombinants:
  """
  Extract recombinants from nextclade output.
  """

  message: """Extracting recombinant candidates from nextclade output.\n
  build:     {{wildcards.build}}
  log:       logs/{rule}/{{wildcards.build}}_{today}.log
  alignment: results/{{wildcards.build}}/nextclade.recombinants.fasta
  strains:   results/{{wildcards.build}}/nextclade.recombinants.txt
  """.format(today=today, rule=rule_name)

  input:
    aligned  = "results/{build}/nextclade.aligned.fasta",
    qc       = "results/{build}/nextclade.qc.tsv",
  output:
    aligned = "results/{build}/nextclade.recombinants.fasta",
    strains = "results/{build}/nextclade.recombinants.txt",
  params:
    custom_ref     = lambda wildcards: _params_nextclade(wildcards)["custom_ref"],
    exclude_clades = lambda wildcards: _params_nextclade_recombinants(wildcards)["exclude_clades"],
  threads: 1
  resources:
    cpus = 1,
  benchmark:
    "benchmarks/{rule}/{{build}}_{today}.tsv".format(today=today, rule=rule_name),
  log:
    "logs/{rule}/{{build}}_{today}.log".format(today=today, rule=rule_name),
  shell:
    """
    # Extract recombinants
    csvtk grep -t -f "clade,Nextclade_pango,qc.overallStatus" -r -p ".*(recombinant|X|bad|mediocre).*" {input.qc} \
      | csvtk grep -t -v -f "clade" -r -p ".*({params.exclude_clades}).*" \
      | csvtk cut -t -f "seqName" \
      | tail -n+2 \
      > {output.strains};

    # Filter Alignment
    seqkit grep -p "{params.custom_ref}" {input.aligned} 1> {output.aligned} 2> {log};
    seqkit grep -f "{output.strains}" {input.aligned} 1>> {output.aligned} 2>> {log};
    """

# -----------------------------------------------------------------------------#
#  STAGE 3: sc2rf
# -----------------------------------------------------------------------------#

rule_name = "sc2rf"

# Parameters function
def _params_sc2rf(wildcards):
  """Parse parameters from wildcards for rule sc2rf."""

  params = {}

  clades = config["builds"][wildcards.build]["sc2rf"]["clades"]
  params["clades"] = "{}".format(" ".join(clades))

  mutation_threshold = config["builds"][wildcards.build]["sc2rf"]["mutation_threshold"]
  params["mutation_threshold"] = "{}".format(mutation_threshold)

  sc2rf_args = config["builds"][wildcards.build]["sc2rf"]["sc2rf_args"]
  params["sc2rf_args"] = "{}".format(sc2rf_args)

  debug_args = config["builds"][wildcards.build]["sc2rf"]["debug_args"]
  params["debug_args"] = "{}".format(debug_args)

  max_name_length = config["builds"][wildcards.build]["sc2rf"]["max_name_length"]
  params["max_name_length"] = "{}".format(max_name_length)     

  return params

# Input function
def _inputs_sc2rf(wildcards):
  """Parse inputs from wildcards for rule sc2rf."""

  inputs = {}

  # exclude_negatives = True. Use alignment from nextclade_recombinants
  # exclude_negatives = False. Use alignment from nextclade
  exclude_negatives = config["builds"][wildcards.build]["nextclade_recombinants"]["exclude_negatives"]

  if exclude_negatives:
    inputs["alignment"] = "results/{build}/nextclade.recombinants.fasta".format(
      build=wildcards.build)
  else:
    inputs["alignment"] = "results/{build}/nextclade.aligned.fasta".format(
      build=wildcards.build)  

  return inputs

# Snakemake rule
rule sc2rf:
  """
  Identify recombinants with sc2rf.
  """

  message: """Identifying recombinants with sc2rf.\n
  build: {{wildcards.build}}
  log:   logs/{rule}/{{wildcards.build}}_{today}.log
  ansi:  results/{{wildcards.build}}/sc2rf.ansi.txt
  csv:   results/{{wildcards.build}}/sc2rf.csv
  """.format(today=today, rule=rule_name)

  input:
    alignment = lambda wildcards: _inputs_sc2rf(wildcards)["alignment"],
  output:
    txt       = "results/{build}/sc2rf.ansi.txt",
    csv       = "results/{build}/sc2rf.csv",
    debug_txt = "results/{build}/sc2rf_debug.ansi.txt",
    debug_csv = "results/{build}/sc2rf_debug.csv",
  params:
    clades               = lambda wildcards: _params_sc2rf(wildcards)["clades"], 
    mutation_threshold   = lambda wildcards: _params_sc2rf(wildcards)["mutation_threshold"], 
    sc2rf_args           = lambda wildcards: _params_sc2rf(wildcards)["sc2rf_args"], 
    debug_args           = lambda wildcards: _params_sc2rf(wildcards)["debug_args"],
    max_name_length      = lambda wildcards: _params_sc2rf(wildcards)["max_name_length"],
    outdir               = lambda wildcards: "results/{build}".format(build=wildcards.build),
  threads: 1
  resources:
    cpus = 1,
  benchmark:
    "benchmarks/{rule}/{{build}}_{today}.tsv".format(today=today, rule=rule_name),
  log:
    regular = "logs/{rule}/{{build}}_{today}.log".format(today=today, rule=rule_name),
    debug   = "logs/{rule}/{{build}}_debug_{today}.log".format(today=today, rule=rule_name),
  shell:
    """

    # Regular Mode
    bash scripts/sc2rf.sh \
      --aligned {input.alignment} \
      --prefix "sc2rf" \
      --outdir {params.outdir} \
      --log {log.regular} \
      --max-name-length {params.max_name_length} \
      --clades "{params.clades}" \
      --mutation-threshold {params.mutation_threshold} \
      {params.sc2rf_args};

    # Debugging Mode (for troubleshooting)
    bash scripts/sc2rf.sh \
      --aligned {input.alignment} \
      --prefix "sc2rf_debug" \
      --outdir {params.outdir} \
      --log {log.debug} \
      --max-name-length {params.max_name_length} \
      --clades "{params.clades}" \
      --mutation-threshold {params.mutation_threshold} \
      {params.debug_args};
    """

# -----------------------------------------------------------------------------

rule_name = "sc2rf_recombinants"

# Parameters function
def _params_sc2rf_recombinants(wildcards):
  """Parse parameters from wildcards for rule sc2rf_recombinants."""

  params = {}

  min_len = config["builds"][wildcards.build]["sc2rf_recombinants"]["min_len"]
  params["min_len"] = "{}".format(min_len)

  max_parents = config["builds"][wildcards.build]["sc2rf_recombinants"]["max_parents"]
  params["max_parents"] = "{}".format(max_parents)

  max_breakpoints = config["builds"][wildcards.build]["sc2rf_recombinants"]["max_breakpoints"]
  params["max_breakpoints"] = "{}".format(max_breakpoints)

  motifs = config["builds"][wildcards.build]["sc2rf_recombinants"]["motifs"]
  if motifs: params["motifs"] = "--motifs {}".format(motifs)
  else: params["motifs"] = ""

  return params

# Snakemake rule
rule sc2rf_recombinants:
  """
  Extract recombinant from sc2rf output.
  """

  message: """Extracting recombinants from sc2rf output.\n
  build:       {{wildcards.build}}
  log:         logs/{rule}/{{wildcards.build}}_{today}.log
  table:       results/{{wildcards.build}}/sc2rf.recombinants.tsv
  ansi:        results/{{wildcards.build}}/sc2rf.recombinants.ansi.txt
  alignment:   results/{{wildcards.build}}/sc2rf.recombinants.fasta
  """.format(today=today, rule=rule_name)

  input:
    ansi      = "results/{build}/sc2rf.ansi.txt",
    csv       = "results/{build}/sc2rf.csv",
    issues    = "resources/issues.tsv",
    alignment = lambda wildcards: _inputs_sc2rf(wildcards)["alignment"],

  output:
    strains   = "results/{build}/sc2rf.recombinants.txt",
    alignment = "results/{build}/sc2rf.recombinants.fasta",
    ansi      = "results/{build}/sc2rf.recombinants.ansi.txt",
    exclude   = "results/{build}/sc2rf.recombinants.exclude.tsv",
    tsv       = "results/{build}/sc2rf.recombinants.tsv",
  params:
    outdir          = lambda wildcards: "results/{build}".format(build=wildcards.build),
    custom_ref      = lambda wildcards: _params_nextclade(wildcards)["custom_ref"],
    min_len         = lambda wildcards: _params_sc2rf_recombinants(wildcards)["min_len"],    
    max_parents     = lambda wildcards: _params_sc2rf_recombinants(wildcards)["max_parents"],
    max_breakpoints = lambda wildcards: _params_sc2rf_recombinants(wildcards)["max_breakpoints"],
    motifs          = lambda wildcards: _params_sc2rf_recombinants(wildcards)["motifs"],
  threads: 1
  resources:
    cpus = 1,
  benchmark:
    "benchmarks/{rule}/{{build}}_{today}.tsv".format(today=today, rule=rule_name),
  log:
    "logs/{rule}/{{build}}_{today}.log".format(today=today, rule=rule_name),
  shell:
    """
    python3 sc2rf/postprocess.py \
      --csv {input.csv} \
      --ansi {input.ansi} \
      --min-len {params.min_len} \
      --max-parents {params.max_parents} \
      --max-breakpoints {params.max_breakpoints} \
      --outdir {params.outdir} \
      --aligned {input.alignment} \
      --custom-ref "{params.custom_ref}" \
      --issues {input.issues} \
      {params.motifs} \
      2> {log};
    """

# -----------------------------------------------------------------------------#
#  STAGE 3: UShER
# -----------------------------------------------------------------------------#

rule_name = "faToVcf"

# Snakemake rule
rule faToVcf:
  """
  Construct VCF from alignment.
  """
  message: """Constructing VCF from alignment.\n
  build: {{wildcards.build}}
  log:   logs/{rule}/{{wildcards.build}}_{today}.log
  vcf:   results/{{wildcards.build}}/sc2rf.vcf.gz
  """.format(today=today, rule=rule_name)

  input:
    alignment  = "results/{build}/sc2rf.recombinants.fasta",
    prob_sites = "data/reference/problematic_sites.vcf",
  output:
    vcf = "results/{build}/sc2rf.vcf.gz",
  params:
    custom_ref = lambda wildcards: _params_nextclade(wildcards)["custom_ref"],
    prefix     = "results/{build}/sc2rf.vcf",
  threads: 1
  resources:
    cpus = 1,
  benchmark:
    "benchmarks/{rule}/{{build}}_{today}.tsv".format(today=today, rule=rule_name),
  log:
    "logs/{rule}/{{build}}_{today}.log".format(today=today, rule=rule_name),
  shell:
    """
    faToVcf -ambiguousToN -maskSites={input.prob_sites} -ref='{params.custom_ref}' {input.alignment} {params.prefix};
    gzip -f {params.prefix};
    """

# -----------------------------------------------------------------------------
rule_name = "usher_download"

rule usher_download:
  """
  Download UShER protobuf.
  """

  message: """Downloading UShER protobuf.\n
  input:    {{wildcards.input}}
  log:      logs/{rule}/{{wildcards.input}}_{today}.txt
  protobuf: data/{{wildcards.input}}/usher.pb.gz
  metadata: data/{{wildcards.input}}/metadata.txt
  """.format(today=today, rule=rule_name)

  wildcard_constraints:
    input = "|".join(USHER_INPUTS),
  output:
    pb       = "data/{input}/usher.pb.gz",
    metadata = "data/{input}/metadata.tsv",
    ver      = "data/{input}/version.txt",
  params:
    pb_url       = lambda wildcards: config["inputs"][wildcards.input]["pb_url"],
    metadata_url = lambda wildcards: config["inputs"][wildcards.input]["metadata_url"],
    ver_url      = lambda wildcards: config["inputs"][wildcards.input]["ver_url"],
  benchmark:
    "benchmarks/{rule}/{{input}}_{today}.tsv".format(today=today, rule=rule_name),
  log:
    "logs/{rule}/{{input}}_{today}.txt".format(today=today, rule=rule_name),
  threads: 1
  resources:
    cpus = 1,
  shell:
    """
    wget -q -O {output.pb} {params.pb_url};
    wget -q -O {output.metadata}.gz {params.metadata_url};
    wget -q -O {output.ver} {params.ver_url};

    csvtk mutate2 -t -n "dataset" -e '"{wildcards.input}"' {output.metadata}.gz 1> {output.metadata} 2>> {log};

    rm -f {output.metadata}.gz
    """

# -----------------------------------------------------------------------------
rule_name = "usher"
rule usher:
  """
  Place VCF samples with UShER.
  """

  message: """Placing VCF samples with UShER.\n
  build:    {{wildcards.build}}
  log:      logs/{rule}/{{wildcards.build}}_{today}.log
  protobuf: results/{{wildcards.build}}/usher.pb.gz
  """.format(today=today, rule=rule_name)

  input:
    vcf = "results/{build}/sc2rf.vcf.gz",
    pb  = lambda wildcards: "data/{base_input}/usher.pb.gz".format(
            base_input=config["builds"][wildcards.build]["base_input"]
          ),
  output:
    pb              = "results/{build}/usher.pb.gz",
    final_tree      = "results/{build}/final-tree.nh",
    placement_stats = "results/{build}/placement_stats.tsv",
    clades          = "results/{build}/clades.txt",
    mut_paths       = "results/{build}/mutation-paths.txt",
  params:
    outdir = "results/{build}",
  benchmark:
    "benchmarks/{rule}/{{build}}_{today}.tsv".format(today=today, rule=rule_name),
  log:
    "logs/{rule}/{{build}}_{today}.log".format(today=today, rule=rule_name),
  shell:
    """
    usher \
      -i {input.pb} \
      -o {output.pb} \
      -v {input.vcf} \
      --threads {resources.cpus} \
      --outdir {params.outdir} \
      2> {log};
    """

# -----------------------------------------------------------------------------
rule_name = "usher_stats"
rule usher_stats:
  """
  Parse statistics from UShER.
  """
  message: "{wildcards.build} | Parsing statistics from UShER."
  
  input:
    placement_stats = "results/{build}/placement_stats.tsv",
    clades          = "results/{build}/clades.txt",
    mut_paths       = "results/{build}/mutation-paths.txt",
    issue_to_lineage = "resources/issue_to_lineage.tsv",
  output:
    placement_stats = "results/{build}/usher.placement_stats.tsv",
    mut_paths       = "results/{build}/usher.mutation_paths.tsv",
    clades          = "results/{build}/usher.clades.tsv",
  params:
    outdir = "results/{build}",
  benchmark:
    "benchmarks/{rule}/{{build}}_{today}.tsv".format(today=today, rule=rule_name),
  log:
    "logs/{rule}/{{build}}_{today}.log".format(today=today, rule=rule_name),
  shell:
    """
    # Rename and reformat output
    cp -f {input.mut_paths} {output.mut_paths};

    echo -e "strain\\tusher_best_set_difference\\tusher_num_best" > {output.placement_stats};
    sed 's/[[:space:]]*$//' {input.placement_stats} >> {output.placement_stats};

    echo -e "strain\\tusher_clade\\tusher_pango_lineage" > {output.clades};

    # Some UShER trees may have 3 or 4 columns
    num_clade_cols=$(head -n 1 {input.clades} | tr "\\t" "\\n" | wc -l)
    if [[ $num_clade_cols -eq 4 ]]; then
      csvtk cut -t -H -f 1,2,4 {input.clades} >> {output.clades};
    else
      cat {input.clades} >> {output.clades};
    fi

    csvtk mutate -t -f "usher_pango_lineage" -n "usher_pango_lineage_map" {output.clades} \
      | csvtk replace -t -f "usher_pango_lineage_map" -p "proposed([0-9]+)" -k {input.issue_to_lineage} -r "{{kv}}" \
      1> {output.clades}.tmp 2>> {log};
    mv {output.clades}.tmp {output.clades}
    """

# -----------------------------------------------------------------------------
rule_name = "usher_metadata"
rule usher_metadata:
  """
  Merge metadata for UShER protobuf.
  """
  message: "{wildcards.build} | Merging metadata for UShER protobuf."
  wildcard_constraints:
    mode = "|".join(LOCAL_INPUTS),
  input:
    input_metadata = "data/{build}/metadata.tsv",
    base_metadata  = lambda wildcards: "data/{base_input}/metadata.tsv".format(
            base_input=config["builds"][wildcards.build]["base_input"]
          ),
    clades        = "results/{build}/usher.clades.tsv",
  output:
    metadata     = "results/{build}/usher.metadata.tsv",
    decimal_date = "results/{build}/usher.metadata.decimal_date.tsv",
  params:
    base_input      = lambda wildcards: config["builds"][wildcards.build]["base_input"],
    extra_cols      = lambda wildcards: config["builds"][wildcards.build]["usher_metadata"]["extra_cols"],
    low_memory_mode =  lambda wildcards: config["builds"][wildcards.build]["usher_subtree"]["low_memory_mode"],
  threads: 1
  resources:
    cpus = 1,
  benchmark:
    "benchmarks/{rule}/{{build}}_{today}.tsv".format(today=today, rule=rule_name),
  log:
    "logs/{rule}/{{build}}_{today}.log".format(today=today, rule=rule_name),
  shell:
    """
    if [[ "{params.extra_cols}" ]]; then extra_cols="--extra-cols {params.extra_cols}"; else extra_cols=""; fi
    if [[ "{params.low_memory_mode}" == "True" ]]; then
      cmd="cp {input.input_metadata} {output.metadata}";
    else
      cmd="bash scripts/usher_metadata.sh --base-input {params.base_input} --build {wildcards.build} $extra_cols 1> {output.metadata} 2> {log}";
    fi;
    eval $cmd

    # Convert date col to decimal date
    python3 scripts/date_to_decimal.py {output.metadata} {output.decimal_date} >> {log} 2>&1;
    """

# -----------------------------------------------------------------------------
# The outdir param doesn't work correctly, hence the cd and relative paths

rule_name = "usher_subtree"
rule usher_subtree:
  """
  Create subtrees from UShER protobuf.
  """
  message: "{wildcards.build} | Creating subtrees from UShER protobuf."
  input:
    pb       = "results/{build}/usher.pb.gz",
    metadata = "results/{build}/usher.metadata.decimal_date.tsv",
    samples  = "results/{build}/sc2rf.recombinants.txt",
  output:
    subtrees_dir = directory("results/{build}/subtrees"),
  params:
    k           = lambda wildcards: config["builds"][wildcards.build]["usher_subtree"]["k"],
    base_input  = lambda wildcards: config["builds"][wildcards.build]["base_input"],
  benchmark:
    "benchmarks/{rule}/{{build}}_{today}.tsv".format(today=today, rule=rule_name),
  log:
    "logs/{rule}/{{build}}_{today}.log".format(today=today, rule=rule_name),
  shell:
    """
    mkdir -p {output.subtrees_dir}
    cd {output.subtrees_dir}
    matUtils extract \
      -i ../../../{input.pb} \
      --nearest-k-batch ../../../{input.samples}:{params.k} \
      -M ../../../{input.metadata} \
      --threads {resources.cpus} \
      > ../../../{log} 2>&1;
    cd - >> ../../../{log}
    """


rule_name = "usher_subtree_collapse"
rule usher_subtree_collapse:
  """
  Collapse duplicate UShER subtrees.
  """
  message: "{wildcards.build} | Collapsing duplicate UShER subtrees."
  input:
    subtrees_dir = directory("results/{build}/subtrees"),
  output:
    collapse_dir = directory("results/{build}/subtrees_collapse"),
    metadata     = "results/{build}/subtrees_collapse/metadata.tsv",
  threads: 1
  resources:
    cpus = 1,
  benchmark:
    "benchmarks/{rule}/{{build}}_{today}.tsv".format(today=today, rule=rule_name),
  log:
    "logs/{rule}/{{build}}_{today}.log".format(today=today, rule=rule_name),
  shell:
    """
    mkdir -p {output.collapse_dir};
    python3 scripts/usher_collapse.py --indir {input.subtrees_dir} --outdir {output.collapse_dir} >> {log} 2>&1;
    """


# -----------------------------------------------------------------------------#
#  STAGE 4: Summarize and Report
# -----------------------------------------------------------------------------#

rule_name = "summary"
rule summary:
  """
  Summarize results from various tools.
  """
  message: "{wildcards.build} | Summarizing results from various tools."
  input:
    nextclade        = "results/{build}/nextclade.metadata.tsv",
    sc2rf            = "results/{build}/sc2rf.recombinants.tsv",
    usher_clades     = "results/{build}/usher.clades.tsv",
    usher_placements = "results/{build}/usher.placement_stats.tsv",
    subtrees         = "results/{build}/subtrees_collapse/metadata.tsv",
    usher_ver        = lambda wildcards: "data/{base_input}/version.txt".format(
                        base_input=config["builds"][wildcards.build]["base_input"]
                      ),

  output:
    summary = "results/{build}/summary.tsv",
  params:
    extra_cols         = lambda wildcards: config["builds"][wildcards.build]["usher_metadata"]["extra_cols"],
    nextclade_dataset  = lambda wildcards: config["builds"][wildcards.build]["nextclade_dataset"]["dataset"],
    nextclade_tag      = lambda wildcards: config["builds"][wildcards.build]["nextclade_dataset"]["tag"],
  threads: 1
  resources:
    cpus = 1,
  benchmark:
    "benchmarks/{rule}/{{build}}_{today}.tsv".format(today=today, rule=rule_name),
  log:
    "logs/{rule}/{{build}}_{today}.log".format(today=today, rule=rule_name),
  shell:
    """
    if [[ "{params.extra_cols}" ]]; then extra_cols="--extra-cols {params.extra_cols}"; else extra_cols=""; fi
    cmd="bash scripts/summary.sh \
      --nextclade {input.nextclade} \
      --sc2rf {input.sc2rf} \
      --usher-clades {input.usher_clades} \
      --usher-placements {input.usher_placements} \
      --usher-dataset {input.usher_ver} \
      --subtrees {input.subtrees} \
      $extra_cols \
      --nextclade-dataset {params.nextclade_dataset}_{params.nextclade_tag} \
      1> {output.summary} 2> {log}";
    eval $cmd
    """

# -----------------------------------------------------------------------------#
# Linelist

# Parameters Function
def _params_linelist(wildcards):
  """Parse parameters from wildcards for rule plot."""

  params = {}

  extra_cols = config["builds"][wildcards.build]["usher_metadata"]["extra_cols"]
  if extra_cols: params["extra_cols"] = "--extra_cols {}".format(extra_cols)
  else: params["extra_cols"] = ""

  geo = config["builds"][wildcards.build]["linelist"]["geo"]
  if geo: params["geo"] = "--geo {}".format(geo)
  else: params["geo"] = ""

  max_placements = config["builds"][wildcards.build]["linelist"]["max_placements"]
  if max_placements: params["max_placements"] = "--max_placements {}".format(max_placements)
  else: params["max_placements"] = ""  

  return params


rule_name = "linelist"
rule linelist:
  """
  Create a linelist of recombinant sequences, lineages, and parents.
  """
  message: """Creating a linelist of recombinant sequences, lineages, and parents..\n
  build:             {{wildcards.build}}
  log:               logs/{rule}/{{build}}_{today}.log
  sequences:         results/{{wildcards.build}}/linelist.tsv
  false_positives:   results/{{wildcards.build}}/false_positives.tsv
  lineages:          results/{{wildcards.build}}/recombinants.tsv
  parents:           results/{{wildcards.build}}/parents.tsv

  """.format(today=today, rule=rule_name)

  message: "{wildcards.build} | Creating a linelist of recombinant sequences and types."
  input:
    summary         = "results/{build}/summary.tsv",
    issues          = "resources/issues.tsv",
  output:
    linelist        = "results/{build}/linelist.tsv",
    false_positives = "results/{build}/false_positives.tsv",
    recombinants    = "results/{build}/recombinants.tsv",
    parents         = "results/{build}/parents.tsv",
  params:
    extra_cols     = lambda wildcards: _params_linelist(wildcards)["extra_cols"],
    geo            = lambda wildcards: _params_linelist(wildcards)["geo"],
    max_placements = lambda wildcards: _params_linelist(wildcards)["max_placements"],
  threads: 1
  resources:
    cpus = 1,
  benchmark:
    "benchmarks/{rule}/{{build}}_{today}.tsv".format(today=today, rule=rule_name),
  log:
    "logs/{rule}/{{build}}_{today}.log".format(today=today, rule=rule_name),
  shell:
    """
    # Create the sequence table (linelist) and false_positives
    python3 scripts/linelist.py --summary {input.summary} --issues {input.issues} --max-placements {params.max_placements} $extra_cols > {log} 2>&1;

    # Create the recombinants table
    python3 scripts/recombinants.py --linelist {output.linelist} --geo {params.geo} >> {log} 2>&1;

    # Create the parents table 
    python3 scripts/parents.py --linelist {output.linelist} >> {log} 2>&1;
    """

# -----------------------------------------------------------------------------#
# Plot

rule_name = "plot"

# Parameters Function
def _params_plot(wildcards):
  """Parse parameters from wildcards for rule plot."""

  params = {}

  weeks = config["builds"][wildcards.build]["plot"]["weeks"]
  if weeks: params["weeks"] = "--weeks {}".format(weeks)
  else: params["weeks"] = ""

  min_date = config["builds"][wildcards.build]["plot"]["min_date"]
  if min_date: params["min_date"] = "--min-date {}".format(min_date)
  else: params["min_date"] = ""

  singletons = config["builds"][wildcards.build]["plot"]["singletons"]
  if singletons: params["singletons"] = "--singletons"
  else: params["singletons"] = ""

  geo = config["builds"][wildcards.build]["linelist"]["geo"]
  if geo: params["geo"] = "--geo {}".format(geo)
  else: params["geo"] = ""

  lag = config["builds"][wildcards.build]["plot"]["lag"]
  if lag: params["lag"] = "--lag {}".format(lag)
  else: params["lag"] = ""

  return params

# Snakemake Rule
rule plot:
  """
  Plot results.
  """
  message: """Plotting results.\n
  build:   {{wildcards.build}}
  log:     logs/{rule}/{{build}}_{today}.log
  plots:   results/{{wildcards.build}}/plots
  """.format(today=today, rule=rule_name)

  input:
    linelist   = "results/{build}/linelist.tsv",
  output:
    plots      = directory("results/{build}/plots"),
  params:
    outdir     = "results/{build}/plots",
    weeks      = lambda wildcards: _params_plot(wildcards)["weeks"],
    min_date   = lambda wildcards: _params_plot(wildcards)["min_date"],
    lag        = lambda wildcards: _params_plot(wildcards)["lag"],
    geo        = lambda wildcards: _params_plot(wildcards)["geo"],
    singletons = lambda wildcards: _params_plot(wildcards)["singletons"],   
  threads: 1
  resources:
    cpus = 1,
  benchmark:
    "benchmarks/{rule}/{{build}}_{today}.tsv".format(today=today, rule=rule_name),
  log:
    "logs/{rule}/{{build}}_{today}.log".format(today=today, rule=rule_name),
  shell:
    """
    python3 scripts/plot.py \
      --linelist {input.linelist} \
      --outdir {params.outdir} \
      {params.lag} \
      {params.geo} \
      {params.weeks} \
      {params.min_date} \
      {params.singletons} \
      > {log} 2>&1;
    """

# -----------------------------------------------------------------------------#
# Report

rule_name = "report"

def _params_report(wildcards):
  """Parse parameters from wildcards for rule report."""

  params = {}

  geo = config["builds"][wildcards.build]["linelist"]["geo"]
  if geo: params["geo"] = "--geo {}".format(geo)
  else: params["geo"] = ""

  changelog = config["builds"][wildcards.build]["report"]["changelog"]
  if changelog: params["changelog"] = "--changelog {}".format(changelog)
  else: params["changelog"] = ""

  template = config["builds"][wildcards.build]["report"]["template"]  
  if template: params["template"] = "--template {}".format(template)
  else: params["template"] = ""

  return params

rule report:
  """
  Summarize results into a report.
  """

  message: """Creating excel report and powerpoint slides.\n
  build:   {{wildcards.build}}
  log:     logs/{rule}/{{build}}_{today}.log
  report:  results/{{wildcards.build}}/report.xlsx
  slides:  results/{{wildcards.build}}/report.pptx
  """.format(today=today, rule=rule_name)

  input:
    linelist        = "results/{build}/linelist.tsv",
    recombinants    = "results/{build}/recombinants.tsv",
    parents         = "results/{build}/parents.tsv",
    false_positives = "results/{build}/false_positives.tsv",
    issues          = "resources/issues.tsv",
    plots           = directory("results/{build}/plots"),
  output:
    slides = "results/{build}/report.pptx",
    xlsx   = "results/{build}/report.xlsx",
  params:
    geo       = lambda wildcards: _params_report(wildcards)["geo"],
    changelog = lambda wildcards: _params_report(wildcards)["changelog"],
    template  = lambda wildcards: _params_report(wildcards)["template"],

  threads: 1
  resources:
    cpus = 1,
  benchmark:
    "benchmarks/{rule}/{{build}}_{today}.tsv".format(today=today, rule=rule_name),
  log:
    "logs/{rule}/{{build}}_{today}.log".format(today=today, rule=rule_name),
  shell:
    """
    # Create the excel report
    csvtk csv2xlsx -t -o {output.xlsx} {input.recombinants} {input.linelist} {input.parents} {input.false_positives} {input.issues} > {log} 2>&1;

    # Create the powerpoint slides
    python3 scripts/report.py --plot-dir {input.plots} {params.geo} {params.changelog} {params.template} >> {log} 2>&1;
    """
